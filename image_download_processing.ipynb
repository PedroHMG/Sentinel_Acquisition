{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7750d52-afa6-433f-a3bf-2778a5d826e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "import netCDF4 as nc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "import json\n",
    "\n",
    "from subprocess import run, DEVNULL\n",
    "\n",
    "from torch.nn import Sequential, Sigmoid\n",
    "from torch import from_numpy, inference_mode\n",
    "from torch.nn import DataParallel\n",
    "\n",
    "from monai.networks.nets import SwinUNETR\n",
    "from monai.inferers import sliding_window_inference\n",
    "\n",
    "from pytorch_lightning import LightningModule\n",
    "\n",
    "from zipfile import ZipFile\n",
    "from zipfile import BadZipFile\n",
    "from zipfile import is_zipfile\n",
    "\n",
    "import xmltodict\n",
    "\n",
    "import time\n",
    "\n",
    "import os\n",
    "from os.path import join, exists, getsize, isfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cbcc5ce-3210-4c54-af10-6e3bc138c6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownloadSARSentinel:\n",
    "    def __init__(self, email, \n",
    "             password,\n",
    "             product_list,\n",
    "             satellite=\"sentinel_1\"\n",
    "                ):\n",
    "        self.password = password\n",
    "        self.email = email\n",
    "        self.product_list = product_list\n",
    "        self.satellite = satellite\n",
    "        self.raw_folder = None\n",
    "        self._query_result = None\n",
    "\n",
    "    def query_result(self):\n",
    "        if not isinstance(self._query_result, pd.DataFrame):\n",
    "            self._query_result = self.query_sar()\n",
    "        return self._query_result\n",
    "        \n",
    "    def query_sar(self):\n",
    "        API_URL_NAME = \"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,'S1A') and ContentDate/Start gt 2022-05-03T00:00:00.000Z and ContentDate/Start lt 2022-05-21T00:00:00.000Z\"\n",
    "        API_URL_NAME = \"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,'{name}')\"\n",
    "        query_result = pd.DataFrame()\n",
    "\n",
    "        for product in self.product_list:\n",
    "            json = requests.get(API_URL_NAME.format(name=product)).json()\n",
    "            response_result = pd.DataFrame.from_dict(json['value'])\n",
    "            \n",
    "            if not response_result.empty:\n",
    "                print(\"Found:\", product)\n",
    "                query_result = pd.concat([query_result, response_result])   \n",
    "                time.sleep(0.5)\n",
    "            else:\n",
    "                print(\"Could not find: \", product)\n",
    "\n",
    "        return query_result\n",
    "        \n",
    "    @staticmethod\n",
    "    def create_folder(folder_path, original_name):\n",
    "        if not folder_path:\n",
    "            folder_path = join(os.getcwd(), original_name)\n",
    "            if not exists(folder_path):\n",
    "                os.mkdir(folder_path)\n",
    "\n",
    "        assert exists(folder_path), f\"Path not found: {folder_path}\"\n",
    "        return folder_path\n",
    "\n",
    "    @staticmethod\n",
    "    def is_downloaded(sar_name, folder):\n",
    "        sar_path = join(folder, sar_name + \".zip\")\n",
    "        if exists(sar_path):\n",
    "            #if getsize(sar_path) > 5E9: #ver o tamanho do arquivo para baixar arquivos incompletos\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def return_headers(self):\n",
    "        token_url = 'https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token'\n",
    "        headers = {'Content-Type': 'application/x-www-form-urlencoded'}\n",
    "        data = {\n",
    "            'grant_type': 'password',\n",
    "            'username': self.email,\n",
    "            'password': self.password,\n",
    "            'client_id': 'cdse-public'\n",
    "        }\n",
    "        token_response = requests.post(token_url, headers=headers, data=data).json()\n",
    "        token_url = token_response[\"access_token\"]\n",
    "        download_headers = {\"Authorization\": f\"Bearer {token_url}\"}\n",
    "        return download_headers\n",
    "\n",
    "    def download_products(self, folder, overwrite=False):\n",
    "        download_url = \"https://zipper.dataspace.copernicus.eu/odata/v1/Products({product_id})/$value\"\n",
    "\n",
    "        for index, product in self.query_result().iterrows():\n",
    "            path_product = join(folder, product[\"Name\"] + \".zip\")               \n",
    "            if not DownloadSARSentinel.is_downloaded(product[\"Name\"], folder) or overwrite:\n",
    "                session = requests.Session()\n",
    "                session.headers.update(self.return_headers())\n",
    "                response = session.get(download_url.format(product_id=product[\"Id\"]), headers=self.return_headers(), stream=True)\n",
    "                total_size = int(response.headers.get('Content-Length', 0))\n",
    "                progress_bar = tqdm(total=total_size, unit='B', unit_scale=True, desc=f'Downloading: {product[\"Name\"]}', leave=True)\n",
    "                progress_bar.reset()\n",
    "\n",
    "                with open(path_product, \"wb\") as file:\n",
    "                    for chunk in response.iter_content(chunk_size=8192):\n",
    "                        if chunk:\n",
    "                            file.write(chunk)\n",
    "                            progress_bar.update(len(chunk))\n",
    "                progress_bar.reset()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f851afcb-b8ac-458c-b45b-ac664df60343",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m new_products \u001b[38;5;241m=\u001b[39m DownloadSARSentinel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpedro.meirelles@ufba.br\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThermal1234@\u001b[39m\u001b[38;5;124m\"\u001b[39m, product_list\u001b[38;5;241m=\u001b[39msar_list)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#new_products.query_result()\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[43mnew_products\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_products\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/mnt/camobi_process/new_data/new_SAR_img\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 72\u001b[0m, in \u001b[0;36mDownloadSARSentinel.download_products\u001b[0;34m(self, folder, overwrite)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_products\u001b[39m(\u001b[38;5;28mself\u001b[39m, folder, overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     70\u001b[0m     download_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://zipper.dataspace.copernicus.eu/odata/v1/Products(\u001b[39m\u001b[38;5;132;01m{product_id}\u001b[39;00m\u001b[38;5;124m)/$value\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m index, product \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m     73\u001b[0m         path_product \u001b[38;5;241m=\u001b[39m join(folder, product[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m)               \n\u001b[1;32m     74\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m DownloadSARSentinel\u001b[38;5;241m.\u001b[39mis_downloaded(product[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m\"\u001b[39m], folder) \u001b[38;5;129;01mor\u001b[39;00m overwrite:\n",
      "Cell \u001b[0;32mIn[2], line 16\u001b[0m, in \u001b[0;36mDownloadSARSentinel.query_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquery_result\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query_result, pd\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[0;32m---> 16\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_sar\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query_result\n",
      "Cell \u001b[0;32mIn[2], line 25\u001b[0m, in \u001b[0;36mDownloadSARSentinel.query_sar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     22\u001b[0m query_result \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m product \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproduct_list:\n\u001b[0;32m---> 25\u001b[0m     json \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAPI_URL_NAME\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproduct\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m     26\u001b[0m     response_result \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict(json[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response_result\u001b[38;5;241m.\u001b[39mempty:\n",
      "File \u001b[0;32m/home/camobi/anaconda3/lib/python3.8/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/camobi/anaconda3/lib/python3.8/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/camobi/anaconda3/lib/python3.8/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/home/camobi/anaconda3/lib/python3.8/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/home/camobi/anaconda3/lib/python3.8/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/home/camobi/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py:715\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 715\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    729\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/camobi/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py:404\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 404\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mconn\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[0;32m/home/camobi/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py:1058\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[0;32m-> 1058\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n\u001b[1;32m   1061\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1062\u001b[0m         (\n\u001b[1;32m   1063\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnverified HTTPS request is being made to host \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1068\u001b[0m         InsecureRequestWarning,\n\u001b[1;32m   1069\u001b[0m     )\n",
      "File \u001b[0;32m/home/camobi/anaconda3/lib/python3.8/site-packages/urllib3/connection.py:363\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;66;03m# Add certificate verification\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[1;32m    365\u001b[0m     tls_in_tls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/home/camobi/anaconda3/lib/python3.8/site-packages/urllib3/connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    171\u001b[0m     extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msocket_options\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket_options\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeoutError(\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    181\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m timed out. (connect timeout=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    182\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout),\n\u001b[1;32m    183\u001b[0m     )\n",
      "File \u001b[0;32m/home/camobi/anaconda3/lib/python3.8/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[1;32m     84\u001b[0m         sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 85\u001b[0m     \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sock\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39merror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "QUERY_CSV_PATH = \"/mnt/camobi_2/PHMG/Sentinel_Acquisition/New_sar_img.csv\"\n",
    "FILE_NAME_COLUMN = \"NOME DO ARQUIVO\"\n",
    "RAW_SAFE_FILE = \"/mnt/camobi_process/new_data/new_SAR_img\"\n",
    "UNZIP_SAFE_FILE = \"/mnt/camobi_process/new_data/unzip_sar_img\"\n",
    "query_sar = pd.read_csv(QUERY_CSV_PATH, header=0)[FILE_NAME_COLUMN]\n",
    "\n",
    "sar_list = []\n",
    "\n",
    "for sar_name in query_sar:\n",
    "    sar_path = join(UNZIP_SAFE_FILE, sar_name + \".SAFE\")\n",
    "    if not exists(sar_path):\n",
    "        sar_list.append(sar_name)\n",
    "#print(len(sar_list))\n",
    "\n",
    "new_products = DownloadSARSentinel(\"pedro.meirelles@ufba.br\", \"Thermal1234@\", product_list=sar_list)\n",
    "#new_products.query_result()\n",
    "\n",
    "new_products.download_products(folder=\"/mnt/camobi_process/new_data/new_SAR_img\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1857e985",
   "metadata": {},
   "outputs": [],
   "source": [
    "downlaod_data = DownloadSARSentinel(\"pedro.meirelles@ufba.br\", \"Thermal1234@\", product_list=list(query_sar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40f1b973-297a-41d8-81a6-c2383367f35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentinelProduct:\n",
    "    def __init__(self, name, file_path, nc_graph_path,  rect_corners=None):\n",
    "        self.name = name\n",
    "        self.simple_name = name.split(\".\")[0][-7:-4]\n",
    "        self.rect_corners = rect_corners\n",
    "        self.file_path = file_path\n",
    "        self.nc_graph_path = nc_graph_path\n",
    "        self.unzip_path = None\n",
    "        self.netcdf_path = None\n",
    "\n",
    "    def unzip(self, unzip_folder):\n",
    "        assert exists(unzip_folder), f\"Folder \\\"{unzip_folder}\\\" does not exist!\"\n",
    "        self.unzip_path = join(unzip_folder, self.name + \".SAFE\") \n",
    "        try:\n",
    "            print(\"Unziping:\", self.name)\n",
    "            with ZipFile(self.file_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(unzip_folder)\n",
    "        except BadZipFile:\n",
    "            print(f\"Imposible to unzip: {self.name}. file is incomplete or corrupted!\")\n",
    "\n",
    "    def edit_zip_to_nc(self, netcdf_folder):\n",
    "        with open(self.nc_graph_path) as arquivo:\n",
    "            dados = xmltodict.parse(arquivo.read())\n",
    "\n",
    "        if self.unzip_path:\n",
    "            input_path = self.unzip_path\n",
    "        else:\n",
    "            input_path = self.file_path\n",
    "        \n",
    "        self.netcdf_path = join(netcdf_folder, self.simple_name + \".nc\")\n",
    "        print(self.netcdf_path)\n",
    "        \n",
    "\n",
    "        dados['graph']['node'][0]['parameters']['file'] = input_path \n",
    "        dados['graph']['node'][-1]['parameters']['file'] = self.netcdf_path \n",
    "\n",
    "        print(dados['graph']['node'][0]['parameters']['file'])\n",
    "\n",
    "\n",
    "        with open(self.nc_graph_path, 'w') as arquivo:\n",
    "            arquivo.write(xmltodict.unparse(dados, pretty=True))\n",
    "\n",
    "    def convert_to_netcdf4(self, gpt_path, netcdf_folder):\n",
    "        self.edit_zip_to_nc(netcdf_folder)\n",
    "        shell = run([gpt_path, self.nc_graph_path])#, stdout=DEVNULL, stderr=DEVNULL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9edfa62-0ed5-4e8a-b021-3ae592019e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1A_IW_SLC__1SDV_20170709T000134_20170709T000201_017387_01D0AA_205D\n",
      "S1B_IW_SLC__1SDV_20211121T142946_20211121T143013_029687_038B19_5510\n",
      "S1A_IW_SLC__1SDV_20210805T000201_20210805T000228_039087_049CB9_D205\n",
      "S1A_IW_SLC__1SDV_20210612T235346_20210612T235415_038314_048582_23F3\n",
      "S1B_IW_SLC__1SDV_20211003T014926_20211003T014953_028965_0374DA_4688\n",
      "S1B_IW_SLC__1SDV_20190325T081332_20190325T081359_015508_01D0FD_EBAF\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAR_TO_NC_GRAPH = \"/mnt/camobi_2/PHMG/Sentinel_Acquisition/graphs/ZIP_to_NC.xml\"\n",
    "PATH_TO_GPT = \"/home/camobi/snap/bin/gpt\"\n",
    "PRODUCT_FOLDER = \"/mnt/camobi_process/new_data/new_SAR_img\"\n",
    "UNZIP_FOLDER = \"/mnt/camobi_process/new_data/unzip_sar_img\"\n",
    "NETCDF_FOLDER = \"/mnt/camobi_process/new_data/images_nc\"\n",
    "\n",
    "product_list = []\n",
    "count = 0\n",
    "\n",
    "for product in os.listdir(UNZIP_FOLDER):\n",
    "    abv_name = product[-9:-5] + \".nc\"\n",
    "    test = join(NETCDF_FOLDER, abv_name)\n",
    "    if \"SAFE\" in product and not exists(join(NETCDF_FOLDER, abv_name)):\n",
    "        count += 1\n",
    "        product_name = product[:-5]\n",
    "        print(product_name)\n",
    "        product_path = join(UNZIP_FOLDER, product + \"/\")\n",
    "        product_file = SentinelProduct(product_name, product_path, SAR_TO_NC_GRAPH)\n",
    "        product_list.append(product_file)\n",
    "count\n",
    "#for product in tqdm(product_list):\n",
    "    #product.unzip(UNZIP_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "054ed8e6-c7e4-447e-9400-0e61071b2465",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/camobi_process/new_data/images_nc/S1A_IW_SLC__1SDV_20170709T000134_20170709T000201_017387_01D0AA_205D.nc\n",
      "/mnt/camobi_process/new_data/unzip_sar_img/S1A_IW_SLC__1SDV_20170709T000134_20170709T000201_017387_01D0AA_205D.SAFE/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: org.esa.snap.core.gpf.operators.tooladapter.ToolAdapterIO: Initializing external tool adapters\n",
      "INFO: org.esa.s2tbx.dataio.gdal.GDALVersion: GDAL not found on system. Internal GDAL 3.2.1 from distribution will be used. (f0)\n",
      "INFO: org.esa.s2tbx.dataio.gdal.GDALVersion: Internal GDAL 3.2.1 set to be used by SNAP.\n",
      "INFO: org.esa.snap.core.util.EngineVersionCheckActivator: Please check regularly for new updates for the best SNAP experience.\n",
      "INFO: org.esa.s2tbx.dataio.gdal.GDALVersion: Internal GDAL 3.2.1 set to be used by SNAP.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing processing graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: org.hsqldb.persist.Logger: dataFileCache open start\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenSearch: https://scihub.copernicus.eu/gnss/search?q=platformname:Sentinel-1 AND platformnumber:A AND producttype:AUX_POEORB AND beginposition:[2017-07-01T00:00:000Z TO 2017-07-31T24:00:000Z]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: org.esa.s1tbx.orbits.gpf.ApplyOrbitFileOp: No valid orbit file found for 09-JUL-2017 00:00:34.019405\n",
      "Orbit files may be downloaded from https://scihub.copernicus.eu/gnss/odata/v1/\n",
      "and placed in /home/los/.snap/auxdata/Orbits/Sentinel-1/POEORB/S1A/2017/07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenSearch: https://scihub.copernicus.eu/gnss/search?q=platformname:Sentinel-1 AND platformnumber:A AND producttype:AUX_RESORB AND beginposition:[2017-07-01T00:00:000Z TO 2017-07-31T24:00:000Z]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: org.esa.s1tbx.orbits.gpf.ApplyOrbitFileOp: ApplyOrbit ignoring error and continuing: java.io.IOException: No valid orbit file found for 09-JUL-2017 00:00:34.019405\n",
      "Orbit files may be downloaded from https://scihub.copernicus.eu/gnss/odata/v1/\n",
      "and placed in /home/los/.snap/auxdata/Orbits/Sentinel-1/POEORB/S1A/2017/07\n",
      "7333 [main] INFO serverStartup - Nc4Iosp: NetCDF-4 C library loaded (jna_path='/home/los/.snap/auxdata/netcdf_natives/9.0.0/amd64', libname='netcdf').\n",
      "7337 [main] INFO serverStartup - NetcdfLoader: set log level: old=0 new=0\n",
      "7337 [main] INFO serverStartup - Nc4Iosp: set log level: old=0 new=0\n",
      "org.esa.snap.core.gpf.OperatorException: Not able to write product file: '/mnt/camobi_process/new_data/images_nc/S1A_IW_SLC__1SDV_20170709T000134_20170709T000201_017387_01D0AA_205D.nc'\n",
      "\tat org.esa.snap.core.gpf.common.WriteOp.doExecute(WriteOp.java:319)\n",
      "\tat org.esa.snap.core.gpf.internal.OperatorContext.executeOperator(OperatorContext.java:1300)\n",
      "\tat org.esa.snap.core.gpf.Operator.execute(Operator.java:153)\n",
      "\tat org.esa.snap.core.gpf.graph.GraphProcessor.executeGraph(GraphProcessor.java:198)\n",
      "\tat org.esa.snap.core.gpf.graph.GraphProcessor.executeGraph(GraphProcessor.java:128)\n",
      "\tat org.esa.snap.core.gpf.main.DefaultCommandLineContext.executeGraph(DefaultCommandLineContext.java:86)\n",
      "\tat org.esa.snap.core.gpf.main.CommandLineTool.executeGraph(CommandLineTool.java:547)\n",
      "\tat org.esa.snap.core.gpf.main.CommandLineTool.runGraph(CommandLineTool.java:391)\n",
      "\tat org.esa.snap.core.gpf.main.CommandLineTool.runGraphOrOperator(CommandLineTool.java:287)\n",
      "\tat org.esa.snap.core.gpf.main.CommandLineTool.run(CommandLineTool.java:188)\n",
      "\tat org.esa.snap.core.gpf.main.CommandLineTool.run(CommandLineTool.java:121)\n",
      "\tat org.esa.snap.core.gpf.main.GPT.run(GPT.java:59)\n",
      "\tat org.esa.snap.core.gpf.main.GPT.main(GPT.java:37)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.esa.snap.runtime.Launcher.lambda$run$0(Launcher.java:55)\n",
      "\tat org.esa.snap.runtime.Engine.runClientCode(Engine.java:189)\n",
      "\tat org.esa.snap.runtime.Launcher.run(Launcher.java:51)\n",
      "\tat org.esa.snap.runtime.Launcher.main(Launcher.java:31)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat com.exe4j.runtime.LauncherEngine.launch(LauncherEngine.java:84)\n",
      "\tat com.install4j.runtime.launcher.UnixLauncher.start(UnixLauncher.java:66)\n",
      "\tat install4j.org.esa.snap.runtime.Launcher1159904018.main(Unknown Source)\n",
      "Caused by: java.io.IOException: java.io.IOException: NetCDF: HDF error\n",
      "\tat org.esa.snap.dataio.netcdf.nc.N4Variable$NetCDF4ChunkWriter.writeChunk(N4Variable.java:246)\n",
      "\tat org.esa.snap.dataio.netcdf.nc.ChunkWriter.write(ChunkWriter.java:73)\n",
      "\tat org.esa.snap.dataio.netcdf.nc.N4Variable.write(N4Variable.java:206)\n",
      "\tat org.esa.snap.dataio.netcdf.metadata.profiles.cf.CfTiePointGridPart.encode(CfTiePointGridPart.java:64)\n",
      "\tat org.esa.snap.dataio.netcdf.NetCdfWriteProfile.writeProduct(NetCdfWriteProfile.java:55)\n",
      "\tat org.esa.snap.dataio.netcdf.DefaultNetCdfWriter.writeProductNodesImpl(DefaultNetCdfWriter.java:65)\n",
      "\tat org.esa.snap.core.dataio.AbstractProductWriter.writeProductNodes(AbstractProductWriter.java:111)\n",
      "\tat org.esa.snap.core.gpf.common.WriteOp.doExecute(WriteOp.java:315)\n",
      "\t... 27 more\n",
      "Caused by: java.io.IOException: NetCDF: HDF error\n",
      "\tat ucar.nc2.jni.netcdf.Nc4Iosp.writeData(Nc4Iosp.java:3051)\n",
      "\tat ucar.nc2.jni.netcdf.Nc4Iosp.writeData(Nc4Iosp.java:2996)\n",
      "\tat ucar.nc2.NetcdfFileWriter.write(NetcdfFileWriter.java:1072)\n",
      "\tat org.esa.snap.dataio.netcdf.nc.N4Variable$NetCDF4ChunkWriter.writeChunk(N4Variable.java:244)\n",
      "\t... 34 more\n",
      "\n",
      "Error: Not able to write product file: '/mnt/camobi_process/new_data/images_nc/S1A_IW_SLC__1SDV_20170709T000134_20170709T000201_017387_01D0AA_205D.nc'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90% done.\n",
      "#\n",
      "# A fatal error has been detected by the Java Runtime Environment:\n",
      "#\n",
      "#  SIGSEGV (0xb) at pc=0x00007f93b2b084db, pid=2224221, tid=0x00007f94356f6700\n",
      "#\n",
      "# JRE version: OpenJDK Runtime Environment (Zulu 8.44.0.13-CA-linux64) (8.0_242-b20) (build 1.8.0_242-b20)\n",
      "# Java VM: OpenJDK 64-Bit Server VM (25.242-b20 mixed mode linux-amd64 )\n",
      "# Problematic frame:\n",
      "# C  [libhdf5.so.9.0.0+0xcf4db]  H5F_close+0x22\n",
      "#\n",
      "# Failed to write core dump. Core dumps have been disabled. To enable core dumping, try \"ulimit -c unlimited\" before starting Java again\n",
      "#\n",
      "# An error report file with more information is saved as:\n",
      "# /mnt/camobi_2/PHMG/Sentinel_Acquisition/hs_err_pid2224221.log\n",
      "#\n",
      "# If you would like to submit a bug report, please visit:\n",
      "#   http://www.azulsystems.com/support/\n",
      "#\n",
      "/mnt/camobi_process/new_data/images_nc/S1B_IW_SLC__1SDV_20211121T142946_20211121T143013_029687_038B19_5510.nc\n",
      "/mnt/camobi_process/new_data/unzip_sar_img/S1B_IW_SLC__1SDV_20211121T142946_20211121T143013_029687_038B19_5510.SAFE/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: org.esa.snap.core.gpf.operators.tooladapter.ToolAdapterIO: Initializing external tool adapters\n",
      "INFO: org.esa.s2tbx.dataio.gdal.GDALVersion: GDAL not found on system. Internal GDAL 3.2.1 from distribution will be used. (f0)\n",
      "INFO: org.esa.s2tbx.dataio.gdal.GDALVersion: Internal GDAL 3.2.1 set to be used by SNAP.\n",
      "INFO: org.esa.snap.core.util.EngineVersionCheckActivator: Please check regularly for new updates for the best SNAP experience.\n",
      "INFO: org.esa.s2tbx.dataio.gdal.GDALVersion: Internal GDAL 3.2.1 set to be used by SNAP.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing processing graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: org.hsqldb.persist.Logger: dataFileCache open start\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenSearch: https://scihub.copernicus.eu/gnss/search?q=platformname:Sentinel-1 AND platformnumber:B AND producttype:AUX_POEORB AND beginposition:[2021-11-01T00:00:000Z TO 2021-11-31T24:00:000Z]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: org.esa.s1tbx.orbits.gpf.ApplyOrbitFileOp: No valid orbit file found for 21-NOV-2021 14:28:47.000000\n",
      "Orbit files may be downloaded from https://scihub.copernicus.eu/gnss/odata/v1/\n",
      "and placed in /home/los/.snap/auxdata/Orbits/Sentinel-1/POEORB/S1B/2021/11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenSearch: https://scihub.copernicus.eu/gnss/search?q=platformname:Sentinel-1 AND platformnumber:B AND producttype:AUX_RESORB AND beginposition:[2021-11-01T00:00:000Z TO 2021-11-31T24:00:000Z]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: org.esa.s1tbx.orbits.gpf.ApplyOrbitFileOp: ApplyOrbit ignoring error and continuing: java.io.IOException: No valid orbit file found for 21-NOV-2021 14:28:47.000000\n",
      "Orbit files may be downloaded from https://scihub.copernicus.eu/gnss/odata/v1/\n",
      "and placed in /home/los/.snap/auxdata/Orbits/Sentinel-1/POEORB/S1B/2021/11\n",
      "6482 [main] INFO serverStartup - Nc4Iosp: NetCDF-4 C library loaded (jna_path='/home/los/.snap/auxdata/netcdf_natives/9.0.0/amd64', libname='netcdf').\n",
      "6486 [main] INFO serverStartup - NetcdfLoader: set log level: old=0 new=0\n",
      "6486 [main] INFO serverStartup - Nc4Iosp: set log level: old=0 new=0\n",
      "org.esa.snap.core.gpf.OperatorException: Not able to write product file: '/mnt/camobi_process/new_data/images_nc/S1B_IW_SLC__1SDV_20211121T142946_20211121T143013_029687_038B19_5510.nc'\n",
      "\tat org.esa.snap.core.gpf.common.WriteOp.doExecute(WriteOp.java:319)\n",
      "\tat org.esa.snap.core.gpf.internal.OperatorContext.executeOperator(OperatorContext.java:1300)\n",
      "\tat org.esa.snap.core.gpf.Operator.execute(Operator.java:153)\n",
      "\tat org.esa.snap.core.gpf.graph.GraphProcessor.executeGraph(GraphProcessor.java:198)\n",
      "\tat org.esa.snap.core.gpf.graph.GraphProcessor.executeGraph(GraphProcessor.java:128)\n",
      "\tat org.esa.snap.core.gpf.main.DefaultCommandLineContext.executeGraph(DefaultCommandLineContext.java:86)\n",
      "\tat org.esa.snap.core.gpf.main.CommandLineTool.executeGraph(CommandLineTool.java:547)\n",
      "\tat org.esa.snap.core.gpf.main.CommandLineTool.runGraph(CommandLineTool.java:391)\n",
      "\tat org.esa.snap.core.gpf.main.CommandLineTool.runGraphOrOperator(CommandLineTool.java:287)\n",
      "\tat org.esa.snap.core.gpf.main.CommandLineTool.run(CommandLineTool.java:188)\n",
      "\tat org.esa.snap.core.gpf.main.CommandLineTool.run(CommandLineTool.java:121)\n",
      "\tat org.esa.snap.core.gpf.main.GPT.run(GPT.java:59)\n",
      "\tat org.esa.snap.core.gpf.main.GPT.main(GPT.java:37)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.esa.snap.runtime.Launcher.lambda$run$0(Launcher.java:55)\n",
      "\tat org.esa.snap.runtime.Engine.runClientCode(Engine.java:189)\n",
      "\tat org.esa.snap.runtime.Launcher.run(Launcher.java:51)\n",
      "\tat org.esa.snap.runtime.Launcher.main(Launcher.java:31)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat com.exe4j.runtime.LauncherEngine.launch(LauncherEngine.java:84)\n",
      "\tat com.install4j.runtime.launcher.UnixLauncher.start(UnixLauncher.java:66)\n",
      "\tat install4j.org.esa.snap.runtime.Launcher1159904018.main(Unknown Source)\n",
      "Caused by: java.io.IOException: java.io.IOException: NetCDF: HDF error\n",
      "\tat org.esa.snap.dataio.netcdf.nc.N4Variable$NetCDF4ChunkWriter.writeChunk(N4Variable.java:246)\n",
      "\tat org.esa.snap.dataio.netcdf.nc.ChunkWriter.write(ChunkWriter.java:73)\n",
      "\tat org.esa.snap.dataio.netcdf.nc.N4Variable.write(N4Variable.java:206)\n",
      "\tat org.esa.snap.dataio.netcdf.metadata.profiles.cf.CfTiePointGridPart.encode(CfTiePointGridPart.java:64)\n",
      "\tat org.esa.snap.dataio.netcdf.NetCdfWriteProfile.writeProduct(NetCdfWriteProfile.java:55)\n",
      "\tat org.esa.snap.dataio.netcdf.DefaultNetCdfWriter.writeProductNodesImpl(DefaultNetCdfWriter.java:65)\n",
      "\tat org.esa.snap.core.dataio.AbstractProductWriter.writeProductNodes(AbstractProductWriter.java:111)\n",
      "\tat org.esa.snap.core.gpf.common.WriteOp.doExecute(WriteOp.java:315)\n",
      "\t... 27 more\n",
      "Caused by: java.io.IOException: NetCDF: HDF error\n",
      "\tat ucar.nc2.jni.netcdf.Nc4Iosp.writeData(Nc4Iosp.java:3051)\n",
      "\tat ucar.nc2.jni.netcdf.Nc4Iosp.writeData(Nc4Iosp.java:2996)\n",
      "\tat ucar.nc2.NetcdfFileWriter.write(NetcdfFileWriter.java:1072)\n",
      "\tat org.esa.snap.dataio.netcdf.nc.N4Variable$NetCDF4ChunkWriter.writeChunk(N4Variable.java:244)\n",
      "\t... 34 more\n",
      "\n",
      "Error: Not able to write product file: '/mnt/camobi_process/new_data/images_nc/S1B_IW_SLC__1SDV_20211121T142946_20211121T143013_029687_038B19_5510.nc'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90% done.\n",
      "#\n",
      "# A fatal error has been detected by the Java Runtime Environment:\n",
      "#\n",
      "#  SIGSEGV (0xb) at pc=0x00007f66b75214db, pid=2224306, tid=0x00007f681c227700\n",
      "#\n",
      "# JRE version: OpenJDK Runtime Environment (Zulu 8.44.0.13-CA-linux64) (8.0_242-b20) (build 1.8.0_242-b20)\n",
      "# Java VM: OpenJDK 64-Bit Server VM (25.242-b20 mixed mode linux-amd64 )\n",
      "# Problematic frame:\n",
      "# C  [libhdf5.so.9.0.0+0xcf4db]  H5F_close+0x22\n",
      "#\n",
      "# Failed to write core dump. Core dumps have been disabled. To enable core dumping, try \"ulimit -c unlimited\" before starting Java again\n",
      "#\n",
      "# An error report file with more information is saved as:\n",
      "# /mnt/camobi_2/PHMG/Sentinel_Acquisition/hs_err_pid2224306.log\n",
      "#\n",
      "# If you would like to submit a bug report, please visit:\n",
      "#   http://www.azulsystems.com/support/\n",
      "#\n",
      "/mnt/camobi_process/new_data/images_nc/S1A_IW_SLC__1SDV_20210805T000201_20210805T000228_039087_049CB9_D205.nc\n",
      "/mnt/camobi_process/new_data/unzip_sar_img/S1A_IW_SLC__1SDV_20210805T000201_20210805T000228_039087_049CB9_D205.SAFE/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: org.esa.snap.core.gpf.operators.tooladapter.ToolAdapterIO: Initializing external tool adapters\n",
      "INFO: org.esa.s2tbx.dataio.gdal.GDALVersion: GDAL not found on system. Internal GDAL 3.2.1 from distribution will be used. (f0)\n",
      "INFO: org.esa.s2tbx.dataio.gdal.GDALVersion: Internal GDAL 3.2.1 set to be used by SNAP.\n",
      "INFO: org.esa.snap.core.util.EngineVersionCheckActivator: Please check regularly for new updates for the best SNAP experience.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[185], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m product \u001b[38;5;129;01min\u001b[39;00m product_list:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mproduct\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_netcdf4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPATH_TO_GPT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNETCDF_FOLDER\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m product_list\n",
      "Cell \u001b[0;32mIn[183], line 46\u001b[0m, in \u001b[0;36mSentinelProduct.convert_to_netcdf4\u001b[0;34m(self, gpt_path, netcdf_folder)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_netcdf4\u001b[39m(\u001b[38;5;28mself\u001b[39m, gpt_path, netcdf_folder):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medit_zip_to_nc(netcdf_folder)\n\u001b[0;32m---> 46\u001b[0m     shell \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnc_graph_path\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/camobi/anaconda3/lib/python3.8/subprocess.py:495\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 495\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    497\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m/home/camobi/anaconda3/lib/python3.8/subprocess.py:1020\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1018\u001b[0m         stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1019\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1020\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/home/camobi/anaconda3/lib/python3.8/subprocess.py:1083\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1081\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1083\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1085\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1087\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/home/camobi/anaconda3/lib/python3.8/subprocess.py:1822\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1821\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 1822\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1823\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   1824\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   1825\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   1826\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid:\n",
      "File \u001b[0;32m/home/camobi/anaconda3/lib/python3.8/subprocess.py:1780\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1778\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1780\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[1;32m   1782\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   1785\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for product in product_list:\n",
    "    product.convert_to_netcdf4(PATH_TO_GPT, NETCDF_FOLDER)\n",
    "\n",
    "product_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf87e12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PedroNet(LightningModule): #out_channels = numero de classes\n",
    "    def __init__(self, img_size, lr,\n",
    "                 depths=(2, 2, 2, 2), \n",
    "                 num_heads=(3, 6, 12, 24), \n",
    "                 feature_size=24, \n",
    "                 norm_name='instance', \n",
    "                 drop_rate=0.0, \n",
    "                 attn_drop_rate=0.0, \n",
    "                 dropout_path_rate=0.0, \n",
    "                 normalize=True, \n",
    "                 use_checkpoint=False, \n",
    "                 downsample='merging', \n",
    "                 use_v2=False \n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.model = Sequential(SwinUNETR(spatial_dims=2,\n",
    "                                    in_channels=1,\n",
    "                                    out_channels=1,\n",
    "                                    depths=depths,\n",
    "                                    img_size=img_size,\n",
    "                                    feature_size=feature_size,\n",
    "                                    drop_rate=drop_rate,\n",
    "                                    num_heads=num_heads,\n",
    "                                    norm_name=norm_name,\n",
    "                                    attn_drop_rate=attn_drop_rate,\n",
    "                                    dropout_path_rate=dropout_path_rate,\n",
    "                                    normalize=normalize,\n",
    "                                    use_checkpoint=use_checkpoint,\n",
    "                                    downsample=downsample,\n",
    "                                    #use_v2=use_v2, apenas para verses mais recentes\n",
    "                                    ))\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def netcdf_inferece(self, nc_product):\n",
    "        torch_img = from_numpy(np.asarray(nc_product.nc_img)).to(\"cuda\")\n",
    "        torch_img = torch_img.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        with inference_mode():\n",
    "            model_img = sliding_window_inference(torch_img, \n",
    "                                            roi_size=(512),\n",
    "                                            sw_batch_size=20, \n",
    "                                            predictor=DataParallel(self.model), \n",
    "                                            mode='constant',\n",
    "                                            overlap=0.8,\n",
    "                                            progress=True\n",
    "                                            )\n",
    "\n",
    "            sigmoid_fn = Sigmoid()\n",
    "            model_img = sigmoid_fn(model_img)\n",
    "            model_img = model_img.to(\"cpu\").squeeze()\n",
    "        return model_img\n",
    "\n",
    "class NetcdfProduct:\n",
    "    def __init__(self, product, image_variable='Sigma0_VV_db'):\n",
    "        self.product = product\n",
    "        self.name = product.filepath().split(\"/\")[-1].split(\".\")[0]\n",
    "        self.image_variable = image_variable\n",
    "        self.nc_img = product.variables[self.image_variable][:]\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "\n",
    "    def create_img(self, folder_path):\n",
    "        img_path = join(folder_path, self.name + \".png\")\n",
    "        normalized_img = ((self.nc_img - np.min(self.nc_img)) / (np.max(self.nc_img) - np.min(self.nc_img))) * 255\n",
    "        cv2.imwrite(img_path, normalized_img)\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_polygons(mask):\n",
    "        edited_contours = []\n",
    "        binary_image = np.array(mask)\n",
    "        \n",
    "        contours, hierarchy = cv2.findContours(binary_image.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        for poly in contours:\n",
    "            if len(poly) > 50:\n",
    "                approx = cv2.approxPolyDP(poly, 0.8, True)\n",
    "                approx = np.squeeze(approx)\n",
    "                edited_contours.append(approx)\n",
    "        return edited_contours\n",
    "    \n",
    "    @staticmethod\n",
    "    def mask_to_bool(probs, threshold=0.5):\n",
    "        mask = np.asarray(probs)\n",
    "        mask[mask > threshold] = True\n",
    "        mask[mask < threshold] = False\n",
    "        return mask\n",
    "\n",
    "    def probs_to_labelme(self, probs, folder, threshold=0.5):\n",
    "        mask = NetcdfProduct.mask_to_bool(probs, threshold)\n",
    "        masked_polygons = NetcdfProduct.create_polygons(mask)\n",
    "        labelme_format = {\"version\": \"5.1.1\",\n",
    "                          \"flags\": {},\n",
    "                          \"shapes\": [],\n",
    "                          \"imagePath\": f\"..\\\\Sar_img\\\\{self.name}.png\",  # Update with your image filename\n",
    "                          \"imageData\": None,\n",
    "                          \"imageHeight\": self.product.dimensions[\"y\"].size,\n",
    "                          \"imageWidth\": self.product.dimensions[\"x\"].size\n",
    "                          }\n",
    "\n",
    "        for patch in masked_polygons:\n",
    "            labelme_format[\"shapes\"].append({\n",
    "                \"label\": \"oil\", \n",
    "                \"points\": patch.squeeze().tolist(),\n",
    "                \"group_id\": None,\n",
    "                \"description\": \"\",\n",
    "                \"shape_type\": \"polygon\",\n",
    "                \"flags\": {}\n",
    "            })\n",
    "\n",
    "        auto_labels_path = join(folder, f\"{self.name}.json\")\n",
    "        with open(auto_labels_path, 'w') as json_file:\n",
    "            json.dump(labelme_format, json_file, indent=2)\n",
    "        print(f\"Label \\\"{self.name}.json\\\" created!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e5659c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 69/69 [03:19<00:00,  2.88s/it]\n"
     ]
    }
   ],
   "source": [
    "NETCDF_PRODUCT_PATH = \"/mnt/camobi_process/new_data/images_nc\"\n",
    "\n",
    "list_nc_product = []\n",
    "\n",
    "for nc_data in tqdm(os.listdir(NETCDF_PRODUCT_PATH)):\n",
    "    nc_data_path = join(NETCDF_PRODUCT_PATH, nc_data)\n",
    "    nc_img = nc.Dataset(nc_data_path, 'r')\n",
    "    netcdf_sar = NetcdfProduct(nc_img)\n",
    "    list_nc_product.append(netcdf_sar)\n",
    "    #netcdf_sar.create_img(\"/mnt/camobi_2/PHMG/Sentinel_Acquisition/img_folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "593b67fc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 156/156 [00:59<00:00,  2.63it/s]\n",
      "  1%|         | 1/69 [01:00<1:09:00, 60.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label \"A8A3.json\" created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 25/25 [00:08<00:00,  2.80it/s]\n",
      "  3%|         | 2/69 [01:10<34:09, 30.60s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label \"2EBC.json\" created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 6/6 [00:02<00:00,  2.83it/s]\n",
      "  4%|         | 3/69 [01:12<19:22, 17.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label \"D205.json\" created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 169/169 [01:03<00:00,  2.65it/s]\n",
      "  6%|         | 4/69 [02:18<39:35, 36.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label \"4DB8.json\" created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 169/169 [01:03<00:00,  2.65it/s]\n",
      "  7%|         | 5/69 [03:23<50:11, 47.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label \"0868.json\" created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 171/171 [01:04<00:00,  2.63it/s]\n",
      "  9%|         | 6/69 [04:30<56:27, 53.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label \"F8D3.json\" created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 169/169 [01:03<00:00,  2.65it/s]\n",
      " 10%|         | 7/69 [05:36<59:37, 57.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label \"C094.json\" created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 157/169 [00:59<00:04,  2.64it/s]\n",
      " 10%|         | 7/69 [06:35<58:26, 56.56s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m PedroNet\u001b[38;5;241m.\u001b[39mload_from_checkpoint(WEIGHTS_MODEL)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m nc_image \u001b[38;5;129;01min\u001b[39;00m tqdm(list_nc_product):\n\u001b[0;32m----> 7\u001b[0m     probs \u001b[38;5;241m=\u001b[39m loaded_model\u001b[38;5;241m.\u001b[39mnetcdf_inferece(nc_image)\n\u001b[1;32m      8\u001b[0m     nc_image\u001b[38;5;241m.\u001b[39mprobs_to_labelme(probs, LABELS_FOLDER)\n",
      "Cell \u001b[0;32mIn[15], line 40\u001b[0m, in \u001b[0;36mPedroNet.netcdf_inferece\u001b[0;34m(self, nc_product)\u001b[0m\n\u001b[1;32m     37\u001b[0m torch_img \u001b[38;5;241m=\u001b[39m torch_img\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m inference_mode():\n\u001b[0;32m---> 40\u001b[0m     model_img \u001b[38;5;241m=\u001b[39m sliding_window_inference(torch_img, \n\u001b[1;32m     41\u001b[0m                                     roi_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m512\u001b[39m),\n\u001b[1;32m     42\u001b[0m                                     sw_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, \n\u001b[1;32m     43\u001b[0m                                     predictor\u001b[38;5;241m=\u001b[39mDataParallel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel), \n\u001b[1;32m     44\u001b[0m                                     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     45\u001b[0m                                     overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m     46\u001b[0m                                     progress\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     47\u001b[0m                                     )\n\u001b[1;32m     49\u001b[0m     sigmoid_fn \u001b[38;5;241m=\u001b[39m Sigmoid()\n\u001b[1;32m     50\u001b[0m     model_img \u001b[38;5;241m=\u001b[39m sigmoid_fn(model_img)\n",
      "File \u001b[0;32m/home/camobi/anaconda3/envs/torch/lib/python3.11/site-packages/monai/inferers/utils.py:185\u001b[0m, in \u001b[0;36msliding_window_inference\u001b[0;34m(inputs, roi_size, sw_batch_size, predictor, overlap, mode, sigma_scale, padding_mode, cval, sw_device, device, progress, roi_weight_map, process_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m unravel_slice \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    179\u001b[0m     [\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28mint\u001b[39m(idx \u001b[38;5;241m/\u001b[39m num_win), \u001b[38;5;28mint\u001b[39m(idx \u001b[38;5;241m/\u001b[39m num_win) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(slices[idx \u001b[38;5;241m%\u001b[39m num_win])\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m slice_range\n\u001b[1;32m    181\u001b[0m ]\n\u001b[1;32m    182\u001b[0m window_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m    183\u001b[0m     [convert_data_type(inputs[win_slice], torch\u001b[38;5;241m.\u001b[39mTensor)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m win_slice \u001b[38;5;129;01min\u001b[39;00m unravel_slice]\n\u001b[1;32m    184\u001b[0m )\u001b[38;5;241m.\u001b[39mto(sw_device)\n\u001b[0;32m--> 185\u001b[0m seg_prob_out \u001b[38;5;241m=\u001b[39m predictor(window_data, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# batched patch segmentation\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# convert seg_prob_out to tuple seg_prob_tuple, this does not allocate new memory.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m seg_prob_tuple: Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n",
      "File \u001b[0;32m/home/camobi/anaconda3/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/home/camobi/anaconda3/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/camobi/anaconda3/envs/torch/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:185\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodule_kwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    184\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 185\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_apply(replicas, inputs, module_kwargs)\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m/home/camobi/anaconda3/envs/torch/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:200\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, replicas: Sequence[T], inputs: Sequence[Any], kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Any]:\n\u001b[0;32m--> 200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parallel_apply(replicas, inputs, kwargs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(replicas)])\n",
      "File \u001b[0;32m/home/camobi/anaconda3/envs/torch/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py:102\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m    100\u001b[0m         thread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m thread \u001b[38;5;129;01min\u001b[39;00m threads:\n\u001b[0;32m--> 102\u001b[0m         thread\u001b[38;5;241m.\u001b[39mjoin()\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     _worker(\u001b[38;5;241m0\u001b[39m, modules[\u001b[38;5;241m0\u001b[39m], inputs[\u001b[38;5;241m0\u001b[39m], kwargs_tup[\u001b[38;5;241m0\u001b[39m], devices[\u001b[38;5;241m0\u001b[39m], streams[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m/home/camobi/anaconda3/envs/torch/lib/python3.11/threading.py:1112\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock()\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1114\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/home/camobi/anaconda3/envs/torch/lib/python3.11/threading.py:1132\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lock\u001b[38;5;241m.\u001b[39macquire(block, timeout):\n\u001b[1;32m   1133\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LABELS_FOLDER = \"/mnt/camobi_2/PHMG/Sentinel_Acquisition/auto_labels\"\n",
    "WEIGHTS_MODEL = \"/mnt/camobi_2/PHMG/PedroSwinNet/Model_512Img_24Feature_(2, 2, 2, 2)depths_0.0attnDrop_(3, 6, 12, 24)Heads_30.000000Lr_0drop_v1/model-Val_loss=0.003714-Val_Precision=0.973-Recall=0.971-Val_F1_Score=0.972.ckpt\"\n",
    "loaded_model = PedroNet.load_from_checkpoint(WEIGHTS_MODEL)\n",
    "\n",
    "\n",
    "for nc_image in tqdm(list_nc_product):\n",
    "    probs = loaded_model.netcdf_inferece(nc_image)\n",
    "    nc_image.probs_to_labelme(probs, LABELS_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "9640716b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[303], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#plt.imshow(test_mask)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m test_mask_1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mtest_mask\u001b[49m)\n\u001b[1;32m      3\u001b[0m test_mask_1[netcdf_sar\u001b[38;5;241m.\u001b[39mnc_img\u001b[38;5;241m.\u001b[39mmask] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#plt.imshow(test_mask_1)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_mask' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#plt.imshow(test_mask)\n",
    "test_mask_1 = np.array(test_mask)\n",
    "test_mask_1[netcdf_sar.nc_img.mask] = np.nan\n",
    "#plt.imshow(test_mask_1)\n",
    "netcdf_sar.probs_to_labelme(test_mask_1, LABELS_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b255ed9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentinelAcquisition:\n",
    "    def __init__(self, data):\n",
    "        self.column_name = \"product_name\"\n",
    "        self.column_obg_product = \"obj_product\"\n",
    "        self.column_product_path = \"product_path\"\n",
    "        self.column_netcdf_path = \"netcdf_path\"\n",
    "        self.column_obj_netcdf = \"obj_netcdf\"\n",
    "        self.data = pd.DataFrame({self.column_name: data,\n",
    "                                  self.column_obg_product: np.nan,\n",
    "                                  self.column_product_path: np.nan,\n",
    "                                  self.column_netcdf_path: np.nan,\n",
    "                                  self.column_obj_netcdf: np.nan\n",
    "                                 })\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.data.to_string()\n",
    "\n",
    "    def add_products(self, folder, nc_graph_path):\n",
    "        for product in os.listdir(folder):\n",
    "            if \"SAFE\" in product:\n",
    "                product_name = product.split(\".\")[0]\n",
    "                product_path = join(folder, product)\n",
    "                search_result = self.nloc(product_name)\n",
    "                if not search_result.empty:\n",
    "                    product_obj = SentinelProduct(product_name, product_path, nc_graph_path)\n",
    "                    self.data.loc[search_result.index, self.column_product_path] = product_path\n",
    "                    self.data.loc[search_result.index, self.column_obg_product] = product_obj\n",
    "                    \n",
    "                    #display(self.data.loc[search_result.index])\n",
    "                else:\n",
    "                    print(product_name, \"not found\")\n",
    "                    return \n",
    "\n",
    "    def download_products(self, folder):\n",
    "        pending_download = self.data.loc[~self.data.index.isin(self.data.dropna(how=\"any\").index)][self.column_name]\n",
    "        print(pending_download)\n",
    "        pending_download = list(pending_download)\n",
    "        new_products = DownloadSARSentinel(\"pedro.meirelles@ufba.br\", \"Thermal1234@\", product_list=pending_download)\n",
    "        new_products.download_products(folder=folder)\n",
    "\n",
    "    def add_netcdfs(self, folder, image_variable='Sigma0_VV_db'):\n",
    "        for nc_product in os.listdir(folder):\n",
    "            nc_product_path = join(folder, nc_product)\n",
    "            nc_name = nc_product.split(\".\")[0]\n",
    "            search_result = self.nloc(nc_name)\n",
    "\n",
    "    def to_netcdf4(self, folder):\n",
    "        pass\n",
    "        \n",
    "        \n",
    "#class NetcdfProduct:\n",
    "#    def __init__(self, product, image_variable='Sigma0_VV_db'):\n",
    " \n",
    "    \n",
    "# class SentinelProduct:\n",
    "#   def __init__(self, name, file_path, nc_graph_path,  rect_corners=None):               \n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data.iloc[index]\n",
    "\n",
    "    def nloc(self, name):\n",
    "        output = self.data[self.data[self.column_name].str.contains(name)]\n",
    "        if output.empty:\n",
    "            print(name, \"Not found!\")\n",
    "        else:  \n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17311bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C094 Not found!\n"
     ]
    }
   ],
   "source": [
    "SAR_TO_NC_GRAPH = \"/mnt/camobi_2/PHMG/Sentinel_Acquisition/graphs/ZIP_to_NC.xml\"\n",
    "NETCDF_FOLDER =\"/mnt/camobi_process/new_data/images_nc\"\n",
    "data_pd = pd.read_csv(\"/mnt/camobi_2/PHMG/New_sar_img.csv\", header=0)[FILE_NAME_COLUMN]\n",
    "data_pd = list(data_pd.dropna(how=\"all\"))\n",
    "\n",
    "\n",
    "FOLDER_PRODUCT = \"/mnt/camobi_process/new_data/unzip_sar_img\"\n",
    "\n",
    "sar_data = SentinelAcquisition(data_pd)\n",
    "sar_data.add_products(\"/mnt/camobi_process/new_data/unzip_sar_img\", SAR_TO_NC_GRAPH)\n",
    "sar_data.add_netcdfs(NETCDF_FOLDER)\n",
    "#sar_data.download_products(\"/mnt/camobi_process/new_data/new_SAR_img\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63477123-195b-4930-a556-1f8396d8929e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>obj_product</th>\n",
       "      <th>product_path</th>\n",
       "      <th>netcdf_path</th>\n",
       "      <th>obj_netcdf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1A_IW_SLC__1SDV_20181009T171427_20181009T1714...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1B_IW_SLC__1SDV_20181008T172144_20181008T1722...</td>\n",
       "      <td>&lt;__main__.SentinelProduct object at 0x7efbe0a7...</td>\n",
       "      <td>/mnt/camobi_process/new_data/unzip_sar_img/S1B...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S1B_IW_SLC__1SDV_20210120T080527_20210120T0805...</td>\n",
       "      <td>&lt;__main__.SentinelProduct object at 0x7efbe0a7...</td>\n",
       "      <td>/mnt/camobi_process/new_data/unzip_sar_img/S1B...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S1A_IW_SLC__1SDV_20170810T024712_20170810T0247...</td>\n",
       "      <td>&lt;__main__.SentinelProduct object at 0x7efbe0a7...</td>\n",
       "      <td>/mnt/camobi_process/new_data/unzip_sar_img/S1A...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S1A_IW_SLC__1SDV_20170729T024712_20170729T0247...</td>\n",
       "      <td>&lt;__main__.SentinelProduct object at 0x7efbe0b1...</td>\n",
       "      <td>/mnt/camobi_process/new_data/unzip_sar_img/S1A...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S1A_IW_SLC__1SDV_20210612T235346_20210612T2354...</td>\n",
       "      <td>&lt;__main__.SentinelProduct object at 0x7efbe0a7...</td>\n",
       "      <td>/mnt/camobi_process/new_data/unzip_sar_img/S1A...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S1B_IW_SLC__1SDV_20211003T014926_20211003T0149...</td>\n",
       "      <td>&lt;__main__.SentinelProduct object at 0x7efbe0a7...</td>\n",
       "      <td>/mnt/camobi_process/new_data/unzip_sar_img/S1B...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S1B_IW_SLC__1SDV_20211121T142946_20211121T1430...</td>\n",
       "      <td>&lt;__main__.SentinelProduct object at 0x7efbe0a7...</td>\n",
       "      <td>/mnt/camobi_process/new_data/unzip_sar_img/S1B...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S1A_IW_SLC__1SDV_20210805T000201_20210805T0002...</td>\n",
       "      <td>&lt;__main__.SentinelProduct object at 0x7efbe0a7...</td>\n",
       "      <td>/mnt/camobi_process/new_data/unzip_sar_img/S1A...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S1A_IW_SLC__1SDV_20170709T000134_20170709T0002...</td>\n",
       "      <td>&lt;__main__.SentinelProduct object at 0x7efbe0b2...</td>\n",
       "      <td>/mnt/camobi_process/new_data/unzip_sar_img/S1A...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        product_name  \\\n",
       "0  S1A_IW_SLC__1SDV_20181009T171427_20181009T1714...   \n",
       "1  S1B_IW_SLC__1SDV_20181008T172144_20181008T1722...   \n",
       "2  S1B_IW_SLC__1SDV_20210120T080527_20210120T0805...   \n",
       "3  S1A_IW_SLC__1SDV_20170810T024712_20170810T0247...   \n",
       "4  S1A_IW_SLC__1SDV_20170729T024712_20170729T0247...   \n",
       "5  S1A_IW_SLC__1SDV_20210612T235346_20210612T2354...   \n",
       "6  S1B_IW_SLC__1SDV_20211003T014926_20211003T0149...   \n",
       "7  S1B_IW_SLC__1SDV_20211121T142946_20211121T1430...   \n",
       "8  S1A_IW_SLC__1SDV_20210805T000201_20210805T0002...   \n",
       "9  S1A_IW_SLC__1SDV_20170709T000134_20170709T0002...   \n",
       "\n",
       "                                         obj_product  \\\n",
       "0                                                NaN   \n",
       "1  <__main__.SentinelProduct object at 0x7efbe0a7...   \n",
       "2  <__main__.SentinelProduct object at 0x7efbe0a7...   \n",
       "3  <__main__.SentinelProduct object at 0x7efbe0a7...   \n",
       "4  <__main__.SentinelProduct object at 0x7efbe0b1...   \n",
       "5  <__main__.SentinelProduct object at 0x7efbe0a7...   \n",
       "6  <__main__.SentinelProduct object at 0x7efbe0a7...   \n",
       "7  <__main__.SentinelProduct object at 0x7efbe0a7...   \n",
       "8  <__main__.SentinelProduct object at 0x7efbe0a7...   \n",
       "9  <__main__.SentinelProduct object at 0x7efbe0b2...   \n",
       "\n",
       "                                        product_path  netcdf_path  obj_netcdf  \n",
       "0                                                NaN          NaN         NaN  \n",
       "1  /mnt/camobi_process/new_data/unzip_sar_img/S1B...          NaN         NaN  \n",
       "2  /mnt/camobi_process/new_data/unzip_sar_img/S1B...          NaN         NaN  \n",
       "3  /mnt/camobi_process/new_data/unzip_sar_img/S1A...          NaN         NaN  \n",
       "4  /mnt/camobi_process/new_data/unzip_sar_img/S1A...          NaN         NaN  \n",
       "5  /mnt/camobi_process/new_data/unzip_sar_img/S1A...          NaN         NaN  \n",
       "6  /mnt/camobi_process/new_data/unzip_sar_img/S1B...          NaN         NaN  \n",
       "7  /mnt/camobi_process/new_data/unzip_sar_img/S1B...          NaN         NaN  \n",
       "8  /mnt/camobi_process/new_data/unzip_sar_img/S1A...          NaN         NaN  \n",
       "9  /mnt/camobi_process/new_data/unzip_sar_img/S1A...          NaN         NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sar_data.data.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
